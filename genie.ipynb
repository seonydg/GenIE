{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mRN3Wt9EwcFj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22409,"status":"ok","timestamp":1714124123125,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"IBS_CNTawgMF","outputId":"cbe478cf-fce4-43fd-af0e-4ba5ec3ae85f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104721,"status":"ok","timestamp":1714124232713,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"FyaTTH8PwcFm","outputId":"8f190a3e-a233-4f37-874c-7e5523dc060c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"]}],"source":["!pip install torch\n","!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["6d196e6b2c46468caf90411fb892795f","5591caf03ccb4e6caed4e3d193ce1ae4","23166b98c7434cc0b92ff0b76c9e55f5","3bbec00911c8456ea250e3ed18e735d1","02090842a8844674b3688ad0e15cfd30","84b2fa9a0a4049aeb4d90baeb1cd6b47","a61ffd51471f434f821c0d3b459f011e","876192d0308e4a7da22eb2922d98e360","10f850375f6848d1b74e29563d9f5fd0","f78d1274d93b4a3a8bca7a4d67c0df60","f72dcf6b56994814897c951f2ed7afc4","8718b7f80f774f96bfccd64a94a4baee","3ee48a4bbcc9470ea223b7c4601759bf","2652885e6a23453f8079e721bcb89ebd","eb145bec42f54dec83ea2ac4b556a477","ee7617e52fdf482996972821edd749b9","e9f49313698944a7acd149954708e786","0663415a40a94c25b6ec736abc3c0130","30dbef9518c442618f9bce896b4305e7","528331e3931d4a95af92d18657a034ab","c544a43227064d4280870b5936a9cb62","d5d557a5e36a4a0c896d420230fe645d"]},"executionInfo":{"elapsed":2471,"status":"ok","timestamp":1714124451841,"user":{"displayName":"seonyong","userId":"18015838499630991285"},"user_tz":-540},"id":"BN8kR1K9wcFw","outputId":"9daff729-ee15-4318-a8b1-1f742504cca9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d196e6b2c46468caf90411fb892795f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/2.30M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8718b7f80f774f96bfccd64a94a4baee","version_major":2,"version_minor":0},"text/plain":["Generating full split:   0%|          | 0/14237 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","data = load_dataset(\"web_nlg\", 'release_v1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nduj4U5Kw-Yz"},"outputs":[],"source":["# dataset -> WN18RR, FB15-237K"]},{"cell_type":"markdown","metadata":{"id":"dHZ8hw-HyGLl"},"source":["# Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bfz8huceyF6O"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmh5QA7lyF2S"},"outputs":[],"source":["class TransE(Model):\n","\n","\tdef __init__(self, ent_tot, rel_tot, dim = 100, p_norm = 1, norm_flag = True, margin = None, epsilon = None):\n","\t\tsuper(TransE, self).__init__(ent_tot, rel_tot)\n","\t\t\n","\t\tself.dim = dim\n","\t\tself.margin = margin\n","\t\tself.epsilon = epsilon\n","\t\tself.norm_flag = norm_flag\n","\t\tself.p_norm = p_norm\n","\n","\t\tself.ent_embeddings = nn.Embedding(self.ent_tot, self.dim)\n","\t\tself.rel_embeddings = nn.Embedding(self.rel_tot, self.dim)\n","\n","\t\tif margin == None or epsilon == None:\n","\t\t\tnn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n","\t\t\tnn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n","\t\telse:\n","\t\t\tself.embedding_range = nn.Parameter(\n","\t\t\t\ttorch.Tensor([(self.margin + self.epsilon) / self.dim]), requires_grad=False\n","\t\t\t)\n","\t\t\tnn.init.uniform_(\n","\t\t\t\ttensor = self.ent_embeddings.weight.data, \n","\t\t\t\ta = -self.embedding_range.item(), \n","\t\t\t\tb = self.embedding_range.item()\n","\t\t\t)\n","\t\t\tnn.init.uniform_(\n","\t\t\t\ttensor = self.rel_embeddings.weight.data, \n","\t\t\t\ta= -self.embedding_range.item(), \n","\t\t\t\tb= self.embedding_range.item()\n","\t\t\t)\n","\n","\t\tif margin != None:\n","\t\t\tself.margin = nn.Parameter(torch.Tensor([margin]))\n","\t\t\tself.margin.requires_grad = False\n","\t\t\tself.margin_flag = True\n","\t\telse:\n","\t\t\tself.margin_flag = False\n","\n","\n","\tdef _calc(self, h, t, r, mode):\n","\t\tif self.norm_flag:\n","\t\t\th = F.normalize(h, 2, -1)\n","\t\t\tr = F.normalize(r, 2, -1)\n","\t\t\tt = F.normalize(t, 2, -1)\n","\t\tif mode != 'normal':\n","\t\t\th = h.view(-1, r.shape[0], h.shape[-1])\n","\t\t\tt = t.view(-1, r.shape[0], t.shape[-1])\n","\t\t\tr = r.view(-1, r.shape[0], r.shape[-1])\n","\t\tif mode == 'head_batch':\n","\t\t\tscore = h + (r - t)\n","\t\telse:\n","\t\t\tscore = (h + r) - t\n","\t\tscore = torch.norm(score, self.p_norm, -1).flatten()\n","\t\treturn score\n","\n","\tdef forward(self, data):\n","\t\tbatch_h = data['batch_h']\n","\t\tbatch_t = data['batch_t']\n","\t\tbatch_r = data['batch_r']\n","\t\tmode = data['mode']\n","\t\th = self.ent_embeddings(batch_h)\n","\t\tt = self.ent_embeddings(batch_t) #bs x embedding dim\n","\t\tr = self.rel_embeddings(batch_r)\n","\t\tscore = self._calc(h ,t, r, mode)\n","    #margin ranking loss\n","\t\tif self.margin_flag:\n","\t\t\treturn self.margin - score\n","\t\telse:\n","\t\t\treturn score\n","\n","\tdef regularization(self, data):\n","\t\tbatch_h = data['batch_h']\n","\t\tbatch_t = data['batch_t']\n","\t\tbatch_r = data['batch_r']\n","\t\th = self.ent_embeddings(batch_h)\n","\t\tt = self.ent_embeddings(batch_t)\n","\t\tr = self.rel_embeddings(batch_r)\n","\t\tregul = (torch.mean(h ** 2) + \n","\t\t\t\t torch.mean(t ** 2) + \n","\t\t\t\t torch.mean(r ** 2)) / 3\n","\t\treturn regul\n","\n","\tdef predict(self, data):\n","\t\tscore = self.forward(data)\n","\t\tif self.margin_flag:\n","\t\t\tscore = self.margin - score\n","\t\t\treturn score.cpu().data.numpy()\n","\t\telse:\n","\t\t\treturn score.cpu().data.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# embedding lookup -> triple score calc (model by model) -> return, 이과정에서 vector 들이 잘 학습됌."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from .Model import Model # ?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DistMult(Model):\n","\n","\tdef __init__(self, ent_tot, rel_tot, dim = 100, margin = None, epsilon = None):\n","\t\tsuper(DistMult, self).__init__(ent_tot, rel_tot)\n","\n","\t\tself.dim = dim\n","\t\tself.margin = margin\n","\t\tself.epsilon = epsilon\n","\t\tself.ent_embeddings = nn.Embedding(self.ent_tot, self.dim)\n","\t\tself.rel_embeddings = nn.Embedding(self.rel_tot, self.dim)\n","\n","\t\tif margin == None or epsilon == None:\n","\t\t\tnn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n","\t\t\tnn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n","\t\telse:\n","\t\t\tself.embedding_range = nn.Parameter(\n","\t\t\t\ttorch.Tensor([(self.margin + self.epsilon) / self.dim]), requires_grad=False\n","\t\t\t)\n","\t\t\tnn.init.uniform_(\n","\t\t\t\ttensor = self.ent_embeddings.weight.data, \n","\t\t\t\ta = -self.embedding_range.item(), \n","\t\t\t\tb = self.embedding_range.item()\n","\t\t\t)\n","\t\t\tnn.init.uniform_(\n","\t\t\t\ttensor = self.rel_embeddings.weight.data, \n","\t\t\t\ta= -self.embedding_range.item(), \n","\t\t\t\tb= self.embedding_range.item()\n","\t\t\t)\n","\n","\tdef _calc(self, h, t, r, mode):\n","\t\tif mode != 'normal':\n","\t\t\th = h.view(-1, r.shape[0], h.shape[-1])\n","\t\t\tt = t.view(-1, r.shape[0], t.shape[-1])\n","\t\t\tr = r.view(-1, r.shape[0], r.shape[-1])\n","\t\tif mode == 'head_batch':\n","\t\t\tscore = h * (r * t)\n","\t\telse:\n","\t\t\tscore = (h * r) * t\n","\t\tscore = torch.sum(score, -1).flatten()\n","\t\treturn score\n","\n","\tdef forward(self, data):\n","\t\tbatch_h = data['batch_h']\n","\t\tbatch_t = data['batch_t']\n","\t\tbatch_r = data['batch_r']\n","\t\tmode = data['mode']\n","\t\th = self.ent_embeddings(batch_h)\n","\t\tt = self.ent_embeddings(batch_t)\n","\t\tr = self.rel_embeddings(batch_r)\n","\t\tscore = self._calc(h ,t, r, mode)\n","\t\treturn score\n","\n","\tdef regularization(self, data):\n","\t\tbatch_h = data['batch_h']\n","\t\tbatch_t = data['batch_t']\n","\t\tbatch_r = data['batch_r']\n","\t\th = self.ent_embeddings(batch_h)\n","\t\tt = self.ent_embeddings(batch_t)\n","\t\tr = self.rel_embeddings(batch_r)\n","\t\tregul = (torch.mean(h ** 2) + torch.mean(t ** 2) + torch.mean(r ** 2)) / 3\n","\t\treturn regul\n","\n","\tdef l3_regularization(self):\n","\t\treturn (self.ent_embeddings.weight.norm(p = 3)**3 + self.rel_embeddings.weight.norm(p = 3)**3)\n","\n","\tdef predict(self, data):\n","\t\tscore = -self.forward(data)\n","\t\treturn score.cpu().data.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from .Model import Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# complex space -> real dim, imaginary dim\n","class ComplEx(Model):\n","    def __init__(self, ent_tot, rel_tot, dim = 100):\n","        super(ComplEx, self).__init__(ent_tot, rel_tot)\n","\n","        self.dim = dim\n","        self.ent_re_embeddings = nn.Embedding(self.ent_tot, self.dim)\n","        self.ent_im_embeddings = nn.Embedding(self.ent_tot, self.dim)\n","        self.rel_re_embeddings = nn.Embedding(self.rel_tot, self.dim)\n","        self.rel_im_embeddings = nn.Embedding(self.rel_tot, self.dim)\n","\n","        nn.init.xavier_uniform_(self.ent_re_embeddings.weight.data)\n","        nn.init.xavier_uniform_(self.ent_im_embeddings.weight.data)\n","        nn.init.xavier_uniform_(self.rel_re_embeddings.weight.data)\n","        nn.init.xavier_uniform_(self.rel_im_embeddings.weight.data)\n","\n","    # (a+bi)(c+di)\n","    def _calc(self, h_re, h_im, t_re, t_im, r_re, r_im):\n","        return torch.sum(\n","            h_re * t_re * r_re\n","            + h_im * t_im * r_re\n","            + h_re * t_im * r_im\n","            - h_im * t_re * r_im,\n","            -1\n","        )\n","\n","    def forward(self, h, r, t, n):\n","        h_re = self.ent_re_embeddings(h)\n","        h_im = self.ent_im_embeddings(h)\n","        t_re = self.ent_re_embeddings(t)\n","        t_im = self.ent_im_embeddings(t)\n","        r_re = self.rel_re_embeddings(r)\n","        r_im = self.rel_im_embeddings(r)\n","        n_re = self.ent_re_embeddings(n)\n","        n_im = self.ent_im_embeddings(n)\n","        pos_score = self._calc(h_re, h_im, t_re, t_im, r_re, r_im)\n","        neg_score = self._calc(n_re, n_im, t_re, t_im, r_re, r_im)\n","        neg_score_tail = self._calc(h_re, h_im, t_re, t_im, n_re, n_im)\n","        return pos_scorem, neg_score, neg_score_tail\n","\n","    def regularization(self, data):\n","        batch_h = data['batch_h']\n","        batch_t = data['batch_t']\n","        batch_r = data['batch_r']\n","        h_re = self.ent_re_embeddings(batch_h)\n","        h_im = self.ent_im_embeddings(batch_h)\n","        t_re = self.ent_re_embeddings(batch_t)\n","        t_im = self.ent_im_embeddings(batch_t)\n","        r_re = self.rel_re_embeddings(batch_r)\n","        r_im = self.rel_im_embeddings(batch_r)\n","        regul = (torch.mean(h_re ** 2) + \n","                 torch.mean(h_im ** 2) + \n","                 torch.mean(t_re ** 2) +\n","                 torch.mean(t_im ** 2) +\n","                 torch.mean(r_re ** 2) +\n","                 torch.mean(r_im ** 2)) / 6\n","        return regul\n","\n","    def predict(self, data):\n","        score = -self.forward(data)\n","        return score.cpu().data.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch, os\n","import json\n","\n","ent2id = dict()\n","id2ent = set()\n","rel2id = dict()\n","id2rel = set()\n","with open('train.txt', 'r') as f:\n","    for line in f:\n","        line = line.strip()\n","        line = line.split('\\t')\n","        id2ent.add(line[0])\n","        id2rel.add(line[1])\n","        id2ent.add(line[2])\n","\n","with open('valid.txt', 'r') as f:\n","    for line in f:\n","        line = line.strip()\n","        line = line.split('\\t')\n","        id2ent.add(line[0])\n","        id2rel.add(line[1])\n","        id2ent.add(line[2])\n","\n","with open('test.txt', 'r') as f:\n","    for line in f:\n","        line = line.strip()\n","        line = line.split('\\t')\n","        id2ent.add(line[0])\n","        id2rel.add(line[1])\n","        id2ent.add(line[2])\n","\n","id2ent = sorted(list(id2ent))\n","id2rel = sorted(list(id2rel))\n","\n","for i,meta in enumerate(id2ent):\n","    ent2id[meta] = i\n","\n","for i,meta in enumerate(id2rel):\n","    rel2id[meta] = i"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","import torch\n","import json\n","import numpy as np\n","\n","class DataSet(Dataset):\n","    def __init__(self, file_path):\n","        self.len = 0\n","        self.head = []\n","        self.rel = []\n","        self.tail = []\n","        self.triple = []\n","        self.negative = []\n","        self.ent2id = torch.load('ent2id.pt')\n","        self.id2ent = torch.load('id2ent.pt')\n","        self.rel2id = torch.load('rel2id.pt')\n","        self.id2rel = torch.load('id2rel.pt')\n","        self.ent_tot = len(self.id2ent)\n","        self.rel_tot = len(self.id2rel)\n","        with open(file_path) as f:\n","            for line in f:\n","                line = line.strip()\n","                line = line.split('\\t')\n","                self.len += 1\n","                self.head.append(int(line[0]))\n","                self.rel.append(int(line[1]))\n","                self.tail.append(int(line[2]))\n","                self.negative.append(np.random.randint(0, len(self.id2ent)))\n","\n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","        return self.head[idx], self.rel[idx], self.tail[idx], self.negative[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 0 23 17000 positive -> true score high\n","# 0 23 74000 negative -> true score negative"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def main():\n","    opts = args\n","    print (\"load data ...\")\n","    train_data = DataSet('data/train2id.txt')\n","    train_loader = DataLoader(train_data, shuffle=True, batch_size=opts.batch_size)\n","    valid_data = DataSet('data/valid2id.txt')\n","    valid_loader = DataLoader(train_data, shuffle=True, batch_size=opts.batch_size)\n","\n","    print(\"save model...\")\n","    torch.save(model.state_dict(), 'kbgat.pt')\n","    print(\"[Saving embeddings of whole entities & relations...]\")\n","\n","    save_embeddings(model, opts, train_data.id2ent, train_data.id2rel)\n","    print(\"[Embedding results are saved successfully.]\")\n","\n","    print(\"load model ...\")\n","    model = TransE(opts, train_data.ent_tot, train_data.rel_tot)\n","    if opts.optimizer == 'Adam':\n","        optimizer = optim.Adam(model.parameters(), lr=opts.lr, weight_decay=opts.weight_decay)\n","    elif opts.optimizer == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=opts.lr)\n","    model.cuda()\n","    loss = nn.MarginRankingLoss(margin=opts.margin)\n","    loss.cuda()\n","    scheduler = torch.optim.lr_scheduler.StepLR(\n","        optimizer, step_size=500, gamma=0.5, last_epoch=-1)\n","\n","    print(\"start training\")\n","    for epoch in range(1, opts.epochs + 1):\n","        print(\"epoch : \" + str(epoch))\n","        model.train()\n","        epoch_start = time.time()\n","        epoch_loss = []\n","        tot = 0\n","        for i, batch_data in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            batch_h, batch_r, batch_t, batch_n = batch_data\n","            batch_h = torch.LongTensor(batch_h).cuda()\n","            batch_r = torch.LongTensor(batch_r).cuda()\n","            batch_t = torch.LongTensor(batch_t).cuda()\n","            batch_n = torch.LongTensor(batch_n).cuda()\n","            pos_score, neg_score = model(batch_h, batch_r, batch_t, batch_n)\n","            train_loss = loss(pos_score, neg_score, -torch.ones(pos_score.size(-1)).cuda())\n","            train_loss.backward()\n","            optimizer.step()\n","            batch_loss = train_loss.item()\n","            epoch_loss.append(batch_loss)\n","            tot += batch_h.size(0)\n","            print('\\r{:>10} epoch {} progress {} loss: {}\\n'.format('', epoch, tot / train_data.__len__(),\n","                                                                    train_loss.item()), end='')\n","        scheduler.step()\n","        end = time.time()\n","        time_used = end - epoch_start\n","        print('one epoch time: {} minutes'.format(time_used / 60))\n","        print('{} epochs'.format(epoch))\n","        print('epoch {} loss: {}'.format(epoch, sum(epoch_loss) / len(epoch_loss)))\n","\n","        with open('transe_log.txt', 'a') as f:\n","            f.write('loss : ' + str(sum(epoch_loss) / len(epoch_loss)) + '\\n')\n","\n","        if epoch % opts.save_step == 0:\n","            print(\"save model...\")\n","            torch.save(model.state_dict(), 'transe.pt')\n","\n","    print(\"save model...\")\n","    torch.save(model.state_dict(), 'transe.pt')\n","    print(\"[Saving embeddings of whole entities & relations...]\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02090842a8844674b3688ad0e15cfd30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0663415a40a94c25b6ec736abc3c0130":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10f850375f6848d1b74e29563d9f5fd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23166b98c7434cc0b92ff0b76c9e55f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_876192d0308e4a7da22eb2922d98e360","max":2296723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10f850375f6848d1b74e29563d9f5fd0","value":2296723}},"2652885e6a23453f8079e721bcb89ebd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30dbef9518c442618f9bce896b4305e7","max":14237,"min":0,"orientation":"horizontal","style":"IPY_MODEL_528331e3931d4a95af92d18657a034ab","value":14237}},"30dbef9518c442618f9bce896b4305e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bbec00911c8456ea250e3ed18e735d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f78d1274d93b4a3a8bca7a4d67c0df60","placeholder":"​","style":"IPY_MODEL_f72dcf6b56994814897c951f2ed7afc4","value":" 2.30M/2.30M [00:00&lt;00:00, 4.32MB/s]"}},"3ee48a4bbcc9470ea223b7c4601759bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9f49313698944a7acd149954708e786","placeholder":"​","style":"IPY_MODEL_0663415a40a94c25b6ec736abc3c0130","value":"Generating full split: 100%"}},"528331e3931d4a95af92d18657a034ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5591caf03ccb4e6caed4e3d193ce1ae4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b2fa9a0a4049aeb4d90baeb1cd6b47","placeholder":"​","style":"IPY_MODEL_a61ffd51471f434f821c0d3b459f011e","value":"Downloading data: 100%"}},"6d196e6b2c46468caf90411fb892795f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5591caf03ccb4e6caed4e3d193ce1ae4","IPY_MODEL_23166b98c7434cc0b92ff0b76c9e55f5","IPY_MODEL_3bbec00911c8456ea250e3ed18e735d1"],"layout":"IPY_MODEL_02090842a8844674b3688ad0e15cfd30"}},"84b2fa9a0a4049aeb4d90baeb1cd6b47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8718b7f80f774f96bfccd64a94a4baee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ee48a4bbcc9470ea223b7c4601759bf","IPY_MODEL_2652885e6a23453f8079e721bcb89ebd","IPY_MODEL_eb145bec42f54dec83ea2ac4b556a477"],"layout":"IPY_MODEL_ee7617e52fdf482996972821edd749b9"}},"876192d0308e4a7da22eb2922d98e360":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a61ffd51471f434f821c0d3b459f011e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c544a43227064d4280870b5936a9cb62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d557a5e36a4a0c896d420230fe645d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9f49313698944a7acd149954708e786":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb145bec42f54dec83ea2ac4b556a477":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c544a43227064d4280870b5936a9cb62","placeholder":"​","style":"IPY_MODEL_d5d557a5e36a4a0c896d420230fe645d","value":" 14237/14237 [00:00&lt;00:00, 9535.89 examples/s]"}},"ee7617e52fdf482996972821edd749b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f72dcf6b56994814897c951f2ed7afc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f78d1274d93b4a3a8bca7a4d67c0df60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
